{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "!pip install datasets -q\n",
    "!pip install tiktoken -q \n",
    "!pip install wandb -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "#wandb_project = 'OpenWebText-GPT2'\n",
    "#wandb.init(project=wandb_project, entity='veetil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBED 768\n",
      "FF_EXP 4\n",
      "LAYERS 12\n",
      "FC_DROPOUT 0.1\n",
      "bias True\n",
      "VOCAB 50304\n",
      "N_HEAD 12\n",
      "ATTN_DROPOUT 0.1\n",
      "RESID_DROPOUT 0.1\n",
      "BLOCK_SIZE 1024\n",
      "EPS 1e-05\n",
      "EMBED_DROPOUT 0.1\n",
      "MAX_POS_EMBED 1024\n",
      "DROPOUT 0.1\n",
      "SWIGLU 1\n",
      "RMS_NORM 1\n",
      "ROTARY_EMBED 1\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch \n",
    "import config\n",
    "config_ = config.read_config()\n",
    "config.print_config(config_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBED 768\n",
      "FF_EXP 4\n",
      "LAYERS 12\n",
      "FC_DROPOUT 0.1\n",
      "bias True\n",
      "VOCAB 50304\n",
      "N_HEAD 12\n",
      "ATTN_DROPOUT 0.1\n",
      "RESID_DROPOUT 0.1\n",
      "BLOCK_SIZE 1024\n",
      "EPS 1e-05\n",
      "EMBED_DROPOUT 0.1\n",
      "MAX_POS_EMBED 1024\n",
      "DROPOUT 0.1\n",
      "SWIGLU 1\n",
      "RMS_NORM 1\n",
      "ROTARY_EMBED 1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "config_ = config.read_config()\n",
    "config.print_config(config_)\n",
    "## instatitate gpt 2 from pytorch and print its architecture\n",
    "#from transformers import GPT2Model\n",
    "#model = GPT2Model.from_pretrained('gpt2')\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "GPT2Model(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(50304, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): RMSNorm()\n",
      "        (attn): SelfAttentionLayer(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): RMSNorm()\n",
      "        (mlp): FeedForwardSwiGLU(\n",
      "          (v): Linear(in_features=768, out_features=2048, bias=False)\n",
      "          (w): Linear(in_features=768, out_features=2048, bias=False)\n",
      "          (c_proj): Linear(in_features=2048, out_features=768, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from gpt import GPT2Model\n",
    "model = GPT2Model(config_)\n",
    "print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[41006, 46996, 48410,  ..., 30214, 12575, 34498],\n",
      "        [22158, 26983, 11622,  ..., 30787,  4106, 31092]])\n",
      "torch.Size([2, 1024])\n"
     ]
    }
   ],
   "source": [
    "## generate x as sequence of tokens from 1 to VOCAB_SIZE of length 10\n",
    "x = torch.randint(0, config_.VOCAB, (2, config_.BLOCK_SIZE))\n",
    "print(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n",
      "applying rotary embedding in attention layer\n",
      "freqs cis shape torch.Size([1024, 32])\n",
      "x shape torch.Size([2, 12, 1024, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.0968,  0.0957,  0.0386,  ..., -0.5720,  0.3649,  1.3545]],\n",
       " \n",
       "         [[-1.0021,  0.5041, -0.0233,  ..., -1.2983,  0.9442, -0.1974]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.weight\n"
     ]
    }
   ],
   "source": [
    "for pn, p in model.named_parameters():\n",
    "    if pn.endswith('c_proj.weight'):\n",
    "        print(pn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_ARM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
