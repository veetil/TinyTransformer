{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers -q\n",
    "import torch.nn as nn \n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBED 768\n",
      "FF_EXP 4\n",
      "LAYERS 12\n",
      "FC_DROPOUT 0.1\n",
      "bias True\n",
      "VOCAB 50304\n",
      "N_HEAD 12\n",
      "ATTN_DROPOUT 0.1\n",
      "RESID_DROPOUT 0.1\n",
      "BLOCK_SIZE 1024\n",
      "EPS 1e-05\n",
      "EMBED_DROPOUT 0.1\n",
      "MAX_POS_EMBED 1024\n",
      "DROPOUT 0.1\n",
      "SWIGLU 1\n",
      "RMS_NORM 1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "config_ = config.read_config()\n",
    "config.print_config(config_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBED 768\n",
      "FF_EXP 4\n",
      "LAYERS 12\n",
      "FC_DROPOUT 0.1\n",
      "bias True\n",
      "VOCAB 50304\n",
      "N_HEAD 12\n",
      "ATTN_DROPOUT 0.1\n",
      "RESID_DROPOUT 0.1\n",
      "BLOCK_SIZE 1024\n",
      "EPS 1e-05\n",
      "EMBED_DROPOUT 0.1\n",
      "MAX_POS_EMBED 1024\n",
      "DROPOUT 0.1\n",
      "SWIGLU 1\n",
      "RMS_NORM 1\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "config_ = config.read_config()\n",
    "config.print_config(config_)\n",
    "## instatitate gpt 2 from pytorch and print its architecture\n",
    "#from transformers import GPT2Model\n",
    "#model = GPT2Model.from_pretrained('gpt2')\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "Instantiating RMSNorm 1\n",
      "Instantiating RMSNorm 2\n",
      "Instantiating SwiGLU\n",
      "GPT2Model(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(50304, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): RMSNorm()\n",
      "        (attn): SelfAttentionLayer(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): RMSNorm()\n",
      "        (mlp): FeedForwardSwiGLU(\n",
      "          (v): Linear(in_features=768, out_features=2048, bias=False)\n",
      "          (w): Linear(in_features=768, out_features=2048, bias=False)\n",
      "          (w2): Linear(in_features=2048, out_features=768, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50304, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from gpt import GPT2Model\n",
    "model = GPT2Model(config_)\n",
    "print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[33534, 47227, 18174,  ...,  8018, 48767, 19486],\n",
      "        [50041, 39828, 28968,  ..., 10384, 31184, 50148]])\n"
     ]
    }
   ],
   "source": [
    "## generate x as sequence of tokens from 1 to VOCAB_SIZE of length 10\n",
    "x = torch.randint(0, config_.VOCAB, (2, config_.BLOCK_SIZE))\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.5945, -0.2053, -0.3184,  ..., -0.0986,  0.5616, -0.7622]],\n",
       " \n",
       "         [[-0.0492, -0.1913,  0.5363,  ...,  0.1291,  0.3054, -0.4783]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_ARM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
